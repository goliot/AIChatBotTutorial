import os
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain.docstore.document import Document

pdf_dir = "./pdfs/"  # PDF íŒŒì¼ì´ ì €ì¥ëœ í´ë” ê²½ë¡œ
documents = []
dirs = os.listdir(pdf_dir)

def combine_docs(path):
    loader = PyPDFLoader(path).load()

    temp_text = ""
    for temp in loader:
        temp_text += temp.page_content + "\n\n"

    return Document(page_content=temp_text)

# 1. PDF í´ë” ë‚´ ëª¨ë“  íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
for dir in dirs:
    full_path = os.path.join(pdf_dir, dir)
    temp_doc = combine_docs(full_path)
    documents.append(temp_doc)

# 2. í…ìŠ¤íŠ¸ ë‚˜ëˆ„ê¸°
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=2000,
    chunk_overlap=100,
)
chunks = text_splitter.split_documents(documents)

# 3. ì„ë² ë”© ìƒì„± ë° ë²¡í„° ì €ì¥ì†Œ êµ¬ì¶•
embeddings = OpenAIEmbeddings()
db = FAISS.from_documents(chunks, embeddings)

# 4. QA ì²´ì¸ êµ¬ì„±
retriever = db.as_retriever()

qa_chain = RetrievalQA.from_chain_type(
    llm=ChatOpenAI(model="gpt-4.1-nano"),
    chain_type='stuff',
    retriever=retriever,
    return_source_documents=True
)

# 5. ì§ˆë¬¸ ë£¨í”„
while True:
    question = input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì¢…ë£Œí•˜ë ¤ë©´ 'exit'): ")
    if question.lower() == "exit":
        break

    result = qa_chain.invoke({"query": question})
    print("ğŸ’¬ ë‹µë³€:", result["result"])
