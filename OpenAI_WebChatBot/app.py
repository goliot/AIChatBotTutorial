import streamlit as st
from dotenv import load_dotenv
import os
from openai import OpenAI, BadRequestError
import pygame
import tempfile
import time
import hashlib
from datetime import datetime

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI()

# pygame ì´ˆê¸°í™”
pygame.mixer.init()

# ìŒì„± íŒŒì¼ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
os.makedirs("speech_files", exist_ok=True)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []
if "model" not in st.session_state:
    st.session_state.model = "gpt-4.1-nano"
if "temperature" not in st.session_state:
    st.session_state.temperature = 0.7
if "voice_model" not in st.session_state:
    st.session_state.voice_model = "tts-1"
if "voice_type" not in st.session_state:
    st.session_state.voice_type = "alloy"
if "voice_instructions" not in st.session_state:
    st.session_state.voice_instructions = ""
if "current_speech" not in st.session_state:
    st.session_state.current_speech = None

# ìŒì„± íŒŒì¼ ê²½ë¡œ ìƒì„± í•¨ìˆ˜
def get_speech_file_path(message_content):
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    content_hash = hashlib.md5(message_content.encode()).hexdigest()[:8]
    return os.path.join("speech_files", f"speech_{timestamp}_{content_hash}.mp3")

# ìŒì„± ìƒì„± ë° ì €ì¥ í•¨ìˆ˜
def generate_and_save_speech(text, file_path):
    with client.audio.speech.with_streaming_response.create(
        model=st.session_state.voice_model,
        voice=st.session_state.voice_type,
        input=text,
        instructions=st.session_state.voice_instructions if st.session_state.voice_instructions else None
    ) as response:
        response.stream_to_file(file_path)
    return file_path

# ìŒì„± ì¬ìƒ ì½œë°± í•¨ìˆ˜
def play_audio(file_path):
    st.session_state.current_speech = file_path
    
# ì‹¤ì œ ìŒì„± ì¬ìƒ í•¨ìˆ˜
def play_speech(file_path):
    pygame.mixer.music.load(file_path)
    pygame.mixer.music.play()
    while pygame.mixer.music.get_busy():
        time.sleep(0.1)
    pygame.mixer.music.unload()

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ì°¨ìˆ˜ë¯¼ ì±—ë´‡", page_icon="ğŸ’¬")

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.title("ì„¤ì • âš™ï¸")
    
    # AI ëª¨ë¸ ì„ íƒ
    model_options = {
        "GPT-4.1 Nano": "gpt-4.1-nano",
        "GPT-3.5 Turbo": "gpt-3.5-turbo",
        "GPT-4": "gpt-4",
        "GPT-4 Turbo": "gpt-4-turbo-preview"
    }
    selected_model = st.selectbox(
        "AI ëª¨ë¸ ì„ íƒ",
        options=list(model_options.keys()),
        index=list(model_options.keys()).index(next(k for k, v in model_options.items() if v == st.session_state.model))
    )
    st.session_state.model = model_options[selected_model]
    
    # Temperature ì„¤ì •
    st.session_state.temperature = st.slider(
        "ì°½ì˜ì„± (Temperature)",
        min_value=0.0,
        max_value=2.0,
        value=st.session_state.temperature,
        step=0.1,
        help="ê°’ì´ ë†’ì„ìˆ˜ë¡ ë” ì°½ì˜ì ì¸ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤. ë‚®ì„ìˆ˜ë¡ ë” ê²°ì •ì ì´ê³  ì¼ê´€ëœ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤."
    )

    # ìŒì„± ì„¤ì • êµ¬ë¶„ì„ 
    st.divider()
    st.subheader("ìŒì„± ì„¤ì • ğŸ¤")

    # ìŒì„± ëª¨ë¸ ì„ íƒ
    voice_model_options = {
        "TTS-1": "tts-1",
        "TTS-1 HD": "tts-1-hd"
    }
    selected_voice_model = st.selectbox(
        "ìŒì„± ëª¨ë¸ ì„ íƒ",
        options=list(voice_model_options.keys()),
        index=list(voice_model_options.keys()).index(next(k for k, v in voice_model_options.items() if v == st.session_state.voice_model))
    )
    st.session_state.voice_model = voice_model_options[selected_voice_model]

    # ëª©ì†Œë¦¬ íƒ€ì… ì„ íƒ
    voice_type_options = {
        "Alloy": "alloy",
        "Echo": "echo",
        "Fable": "fable",
        "Onyx": "onyx",
        "Nova": "nova",
        "Shimmer": "shimmer"
    }
    selected_voice_type = st.selectbox(
        "ëª©ì†Œë¦¬ íƒ€ì… ì„ íƒ",
        options=list(voice_type_options.keys()),
        index=list(voice_type_options.keys()).index(next(k for k, v in voice_type_options.items() if v == st.session_state.voice_type))
    )
    st.session_state.voice_type = voice_type_options[selected_voice_type]

    # ìŒì„± ì§€ì‹œì‚¬í•­ ì„¤ì •
    st.subheader("ìŒì„± ì§€ì‹œì‚¬í•­")
    
    # ë¯¸ë¦¬ ì •ì˜ëœ ì§€ì‹œì‚¬í•­ ì˜µì…˜
    preset_instructions = {
        "ê¸°ë³¸": "",
        "ê±´ë°©ì§„": "ê±´ë°©ì§„ ëª©ì†Œë¦¬",
        "ì¹œê·¼í•œ": "ì¹œê·¼í•˜ê³  ë”°ëœ»í•œ ëª©ì†Œë¦¬",
        "ì§„ì§€í•œ": "ì§„ì§€í•˜ê³  ê¶Œìœ„ìˆëŠ” ëª©ì†Œë¦¬",
        "ì¬ë¯¸ìˆëŠ”": "ì¬ë¯¸ìˆê³  í™œê¸°ì°¬ ëª©ì†Œë¦¬",
        "ìŠ¬í”ˆ": "ìŠ¬í”„ê³  ê°ì •ì ì¸ ëª©ì†Œë¦¬",
        "ì¡°í­": "ì¡°í­ê°™ì€ ë§íˆ¬",
        "ìˆ ì·¨í•œ ì‚¬ëŒ": "ìˆ  ì·¨í•œ ëª©ì†Œë¦¬"
    }
    
    # ì§€ì‹œì‚¬í•­ ì„ íƒ ë°©ì‹
    instruction_mode = st.radio(
        "ì§€ì‹œì‚¬í•­ ì„¤ì • ë°©ì‹",
        ["ë¯¸ë¦¬ ì •ì˜ëœ ì˜µì…˜", "ì§ì ‘ ì…ë ¥"],
        horizontal=True
    )
    
    if instruction_mode == "ë¯¸ë¦¬ ì •ì˜ëœ ì˜µì…˜":
        selected_preset = st.selectbox(
            "ì§€ì‹œì‚¬í•­ ì„ íƒ",
            options=list(preset_instructions.keys()),
            index=list(preset_instructions.keys()).index(next(k for k, v in preset_instructions.items() if v == st.session_state.voice_instructions))
        )
        st.session_state.voice_instructions = preset_instructions[selected_preset]
    else:
        st.session_state.voice_instructions = st.text_input(
            "ì§ì ‘ ì§€ì‹œì‚¬í•­ ì…ë ¥",
            value=st.session_state.voice_instructions,
            placeholder="ì˜ˆ: ê±´ë°©ì§„ ëª©ì†Œë¦¬, ì¹œê·¼í•œ í†¤ìœ¼ë¡œ ë§í•˜ê¸° ë“±"
        )

# íƒ€ì´í‹€
st.title("AI ì±„íŒ…ë°© ğŸ¤–")

# ì±„íŒ… ê¸°ë¡ í‘œì‹œ
for i, message in enumerate(st.session_state.messages):
    with st.chat_message(message["role"]):
        st.write(message["content"])
        
        # AI ì‘ë‹µì—ë§Œ ìŒì„± ì¬ìƒ ë²„íŠ¼ ì¶”ê°€
        if message["role"] == "assistant":
            # ìŒì„± íŒŒì¼ ê²½ë¡œê°€ ì—†ìœ¼ë©´ ìƒì„±
            if "speech_file" not in message:
                speech_file = get_speech_file_path(message["content"])
                if not os.path.exists(speech_file):
                    speech_file = generate_and_save_speech(message["content"], speech_file)
                message["speech_file"] = speech_file
            
            # ìŒì„± ì¬ìƒ ë²„íŠ¼
            st.button("ğŸ”Š ìŒì„± ë‹¤ì‹œ ë“£ê¸°", key=f"play_{i}", on_click=play_audio, args=(message["speech_file"],))

# í˜„ì¬ ì¬ìƒí•  ìŒì„±ì´ ìˆìœ¼ë©´ ì¬ìƒ
if st.session_state.current_speech:
    play_speech(st.session_state.current_speech)
    st.session_state.current_speech = None

# ì‚¬ìš©ì ì…ë ¥
if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."):
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.write(prompt)

    # AI ì‘ë‹µ ìƒì„±
    with st.chat_message("assistant"):
        try:
            # ì‹œìŠ¤í…œ ë©”ì‹œì§€ì— ìŒì„± ì§€ì‹œì‚¬í•­ ë°˜ì˜
            system_message = {
                "role": "system",
                "content": f"ë‹¹ì‹ ì€ {st.session_state.voice_instructions}ë¡œ ëŒ€í™”í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ëª¨ë“  ì‘ë‹µì€ ì´ í†¤ê³¼ ìŠ¤íƒ€ì¼ì„ ìœ ì§€í•´ì•¼ í•©ë‹ˆë‹¤."
            } if st.session_state.voice_instructions else None

            # ë©”ì‹œì§€ ëª©ë¡ ì¤€ë¹„
            messages = [system_message] if system_message else []
            messages.extend([
                {"role": m["role"], "content": m["content"]}
                for m in st.session_state.messages
            ])

            # OpenAI API í˜¸ì¶œ
            response = client.chat.completions.create(
                model=st.session_state.model,
                messages=messages,
                temperature=st.session_state.temperature,
            )
            
            # AI ì‘ë‹µ í‘œì‹œ
            ai_response = response.choices[0].message.content
            st.write(ai_response)
            
            # ìŒì„± íŒŒì¼ ìƒì„± ë° ì €ì¥
            speech_file = get_speech_file_path(ai_response)
            generate_and_save_speech(ai_response, speech_file)
            
            # AI ì‘ë‹µì„ ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            st.session_state.messages.append({
                "role": "assistant",
                "content": ai_response,
                "speech_file": speech_file
            })
            
            # ìŒì„± ì¦‰ì‹œ ì¬ìƒ
            play_speech(speech_file)
            
        except BadRequestError as e:
            st.error(f"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        except Exception as e:
            st.error(f"ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
